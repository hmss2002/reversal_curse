Llama-3.2-3B-Instruct（text only） 
Qwen3-4B
Gemma 3 4B 

同一训练策略：建议统一用 LoRA
同一训练步数口径：例如“看到的 tokens 总量一致”，而不是仅对齐 epoch（不同 tokenizer 会导致每条样本 token 数不同）
同一评测约束：输出格式强约束（例如“只输出名字，不要解释”）

存储示例：
/mnt/models/
  base/
    meta-llama/Llama-3.2-3B-Instruct/
    Qwen/Qwen3-4B-Instruct/
    google/gemma-3-4b-it/
  runs/
    reversal_curse/
      2025-12-19_llama32-3b_lora_seed0/
      2025-12-19_qwen3-4b_lora_seed0/
      2025-12-19_gemma3-4b_lora_seed0/

output_dir=/mnt/models/runs/...

最终 save_pretrained(output_dir) 保存 adapter

推理时再“基座 + adapter 合并加载”