"""本地开源模型复现实验 1（LoRA 微调）相关代码。

注意：这里的实现目标是：
- 不依赖 OpenAI API；
- 支持下载/加载 HuggingFace 开源模型；
- 统一训练策略为 LoRA；
- 用“训练过程中看到的 token 总量(token_budget)”对齐训练步数口径；
- 评测时对输出格式做强约束（例如只输出名字）。

本包尽量不侵入原仓库结构：原来的 Experiment 1/3 主要围绕 OpenAI API，
而这里新增一条“本地训练/本地评测”的路径。
"""
